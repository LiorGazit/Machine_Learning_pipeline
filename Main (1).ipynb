{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is a Multiclassification Pipeline for Text Observations\n",
    "## The pipeline consists of:  \n",
    "1. Gathering the data  \n",
    "1. Processing the data  \n",
    "1. Exploring the data  \n",
    "1. Feature engineering  \n",
    "1. Preliminary feature selection based on univariate proxies  \n",
    "1. ML models selection  \n",
    "1. Training chosen model  \n",
    "1. Generating performance metrics  \n",
    "\n",
    "## The Data:\n",
    "A data set from ??? that holds texts and a class for each.  \n",
    "There are 8 total classes for this set, so the appropriate solution is a NLP-ML classifier.\n",
    "\n",
    "## Approach:\n",
    "A simple generic ML approach.  \n",
    "Meaning, I don't leverage any NLP-dedicated models (like BERT or GPT3).  \n",
    "But rather I design numerical features for the various text terms (One Hot Encoding/Bag of Words/TFIDF), and pipe them into generic ML models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "# ML imports: \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name: The file from Hackerrank that holds the raw data\n",
    "# do_preprocessing: Logical, should preprocessing be performed\n",
    "# do_feature_eng: Logical\n",
    "# do_cleaning: Logical\n",
    "# maximize_a_priori: Logocal, should the univariate preliminary feature selection be based on a priori or a postiori stats\n",
    "# num_chosen_features_per_class: Int, for the preliminary feature selection, how many features should be selected per class\n",
    "# test_size: ratio between 0 - 1\n",
    "# feature_eng_details: Either \"TfidfVectorizer\" (for TFIDF feature eng.) or \"CountVectorizer\" (for one hot encoding)\n",
    "config_dict = {'file_name': \"trainingdata_2.txt\",\n",
    "               'do_preprocessing': True,\n",
    "               'do_feature_eng': True,\n",
    "               'do_cleaning': True,\n",
    "               'maximize_a_priori': True,\n",
    "               'num_chosen_features_per_class': 4,\n",
    "               'test_size': 0.2,\n",
    "               'feature_eng_details': \"CountVectorizer\",\n",
    "               'ngram_range_min': 1,\n",
    "               'ngram_range_max': 2,\n",
    "               'max_features': 2000}\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = pd.read_csv(config_dict[\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_parsed = pd.DataFrame([])\n",
    "# dataset_parsed[[\"class\", \"text\"]] = dataset_raw.iloc[:, 0].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# dataset_parsed.head().style.set_properties(**{'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
